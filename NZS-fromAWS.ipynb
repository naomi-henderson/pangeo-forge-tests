{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF Zarr Sequential Recipe\n",
    "### NOTE - all files and catalogs here are temporary and not ready for general use!!!\n",
    "\n",
    "- Can go to https://aws-cloudnode.esgfed.org/thredds/fileServer/CMIP6 to get a sample netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from cftime import DatetimeNoLeap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.16.2', '2.6.1', '1.3.1', '1.2.1')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the versions are fine for cftime:\n",
    "import zarr\n",
    "import cftime\n",
    "xr.__version__, zarr.__version__, cftime.__version__, pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import s3fs   - don't use, not very reliable with open_dataset (for CNRM models, in particular)\n",
    "#fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s3 = pd.read_csv('http://fletcher.ldeo.columbia.edu/catalogs/s3-world.csv.gz')\n",
    "tests = ['CMIP/MPI-M/MPI-ESM1-2-HR/historical/r1i1p1f1/Amon/tas/gn/v20190710/'\n",
    "        ,'CMIP/NOAA-GFDL/GFDL-CM4/historical/r1i1p1f1/Omon/tos/gn/v20180701/'\n",
    "        ,'CMIP/NASA-GISS/GISS-E2-1-G/historical/r1i1p1f1/Amon/ua/gn/v20180827/'\n",
    "        ,'CMIP/THU/CIESM/piControl/r1i1p1f1/Amon/zg/gr/v20191202/'\n",
    "        ,'CMIP/CNRM-CERFACS/CNRM-ESM2-1/piControl/r1i1p1f2/Amon/co2/gr/v20181115/'\n",
    "        ]\n",
    "files_per_chunk = [10,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://aws-cloudnode.esgfed.org/thredds/fileServer/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/piControl/r1i1p1f2/Amon/co2/gr/v20181115/co2_Amon_CNRM-ESM2-1_piControl_r1i1p1f2_gr_185001-194912.nc',\n",
       " 'https://aws-cloudnode.esgfed.org/thredds/fileServer/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/piControl/r1i1p1f2/Amon/co2/gr/v20181115/co2_Amon_CNRM-ESM2-1_piControl_r1i1p1f2_gr_195001-204912.nc',\n",
       " 'https://aws-cloudnode.esgfed.org/thredds/fileServer/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/piControl/r1i1p1f2/Amon/co2/gr/v20181115/co2_Amon_CNRM-ESM2-1_piControl_r1i1p1f2_gr_205001-214912.nc',\n",
       " 'https://aws-cloudnode.esgfed.org/thredds/fileServer/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/piControl/r1i1p1f2/Amon/co2/gr/v20181115/co2_Amon_CNRM-ESM2-1_piControl_r1i1p1f2_gr_215001-224912.nc',\n",
       " 'https://aws-cloudnode.esgfed.org/thredds/fileServer/CMIP6/CMIP/CNRM-CERFACS/CNRM-ESM2-1/piControl/r1i1p1f2/Amon/co2/gr/v20181115/co2_Amon_CNRM-ESM2-1_piControl_r1i1p1f2_gr_225001-234912.nc']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick a dataset to save as zarr:\n",
    "test_number = 4\n",
    "vstore = tests[test_number]\n",
    "inputs_per_chunk = files_per_chunk[test_number]\n",
    "\n",
    "df_vstore = df_s3[df_s3.vstore == vstore]\n",
    "var = df_vstore.variable_id.unique()[0]\n",
    "# make sure we are looking at the last available version:\n",
    "last_version = sorted(df_vstore.version.unique())[-1]\n",
    "dze = df_vstore[df_vstore.version == last_version].reset_index(drop=True)\n",
    "\n",
    "print(f\"number of files = {len(dze)}\")\n",
    "input_urls = dze.url.to_list()\n",
    "input_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a Recipe:\n",
    "from pangeo_forge.recipe import NetCDFtoZarrSequentialRecipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from fsspec.implementations.local import LocalFileSystem\n",
    "from pangeo_forge.storage import FSSpecTarget, CacheFSSpecTarget\n",
    "\n",
    "fs_local = LocalFileSystem()\n",
    "\n",
    "cache_target = FSSpecTarget(fs_local, root_path='netcdf-tmp')\n",
    "\n",
    "target = FSSpecTarget(fs_local, root_path='zarr-tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of time slices in first file = 1200\n",
      "Dataset size is 2988.473548 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Coordinates:\n",
       "   * lat      (lat) float64 -88.93 -87.54 -86.14 -84.74 ... 86.14 87.54 88.93\n",
       "   * lon      (lon) float64 0.0 1.406 2.812 4.219 ... 354.4 355.8 357.2 358.6\n",
       "   * plev     (plev) float32 1e+05 9.25e+04 8.5e+04 7e+04 ... 1e+03 500.0 100.0\n",
       "   * time     (time) datetime64[ns] 1850-01-16T12:00:00 ... 1949-12-16T12:00:00,\n",
       " Data variables:\n",
       "     time_bounds  (time, axis_nbounds) datetime64[ns] ...\n",
       "     co2          (time, plev, lat, lon) float32 ...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first file from the dataset, using the OPeNDAP url:\n",
    "ncfile = input_urls[0].replace('fileServer','dodsC')\n",
    "ds = xr.open_dataset(ncfile)\n",
    "ntimes = len(ds.time)\n",
    "print(f\"number of time slices in first file = {ntimes}\")\n",
    "print(f\"Dataset size is {ds.nbytes/1e6} MB\")  # Too large - but don't know how to split\n",
    "ds.coords, ds.data_vars"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make sure old way works - yup, just fine:\n",
    "join = 'exact'\n",
    "preprocess = set_bnds_as_coords\n",
    "gfiles = [s.replace('fileServer','dodsC') for s in input_urls]\n",
    "ds_old = xr.open_mfdataset(gfiles,use_cftime=True,\n",
    "                        preprocess=preprocess,\n",
    "                        data_vars='minimal',\n",
    "                        #chunks={'time': chunksize}, \n",
    "                        join=join, combine='nested',\n",
    "                        concat_dim='time')\n",
    "print(ds_old.time)\n",
    "ds_old.ua[0,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetCDFtoZarrSequentialRecipe(sequence_dim='time', inputs_per_chunk=1, nitems_per_input=1200, target=<pangeo_forge.storage.UninitializedTarget object at 0x7f486724d290>, input_cache=<pangeo_forge.storage.UninitializedTarget object at 0x7f4870c741d0>, require_cache=False, consolidate_zarr=True, xarray_open_kwargs={'use_cftime': True, 'decode_coords': False}, xarray_concat_kwargs={}, delete_input_encoding=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if test_number == 1:\n",
    "    recipe = NetCDFtoZarrSequentialRecipe(\n",
    "        input_urls=input_urls,\n",
    "        #xarray_open_kwargs={'preprocess':set_bnds_as_coords},\n",
    "        xarray_open_kwargs={'drop_variables':'height'},\n",
    "        sequence_dim=\"time\",\n",
    "        inputs_per_chunk=inputs_per_chunk,\n",
    "        nitems_per_input=ntimes\n",
    "    )\n",
    "else:\n",
    "    recipe = NetCDFtoZarrSequentialRecipe(\n",
    "        input_urls=input_urls,\n",
    "        sequence_dim=\"time\",\n",
    "        xarray_open_kwargs={'use_cftime':True, 'decode_coords':False},\n",
    "        #xarray_open_kwargs={'decode_times':False},  # this makes a problem with 365_day calendar in recipe.prepare_target()\n",
    "        #xarray_open_kwargs={'use_cftime':True,'decode_times':False}, # recipe.prepare_target() fails when using decode_times\n",
    "        inputs_per_chunk=inputs_per_chunk,\n",
    "        require_cache=False,\n",
    "        nitems_per_input=ntimes\n",
    "    )\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetCDFtoZarrSequentialRecipe(sequence_dim='time', inputs_per_chunk=1, nitems_per_input=1200, target=FSSpecTarget(fs=<fsspec.implementations.local.LocalFileSystem object at 0x7f486b8688d0>, root_path='zarr-tmp'), input_cache=FSSpecTarget(fs=<fsspec.implementations.local.LocalFileSystem object at 0x7f486b8688d0>, root_path='netcdf-tmp'), require_cache=False, consolidate_zarr=True, xarray_open_kwargs={'use_cftime': True, 'decode_coords': False}, xarray_concat_kwargs={}, delete_input_encoding=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the cache and target location\n",
    "recipe.input_cache = cache_target\n",
    "recipe.target = target\n",
    "recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must cache the first chunk as well as any others you want to look at\n",
    "all_chunks = list(recipe.iter_chunks())\n",
    "\n",
    "#for input_file in recipe.inputs_for_chunk(all_chunks[0]):\n",
    "#    print(input_file)\n",
    "#    recipe.cache_input(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid value for attr 'coordinates': Empty(dtype=dtype('S1')) must be a number, a string, an ndarray or a list/tuple of numbers/strings for serialization to netCDF files",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGroupNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/pangeo_forge/recipe.py\u001b[0m in \u001b[0;36m_prepare_target\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Found an existing dataset in target\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/pangeo_forge/recipe.py\u001b[0m in \u001b[0;36mopen_target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mtarget_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_zarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_zarr\u001b[0;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, decode_timedelta, use_cftime, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0mdecode_timedelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_timedelta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0muse_cftime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cftime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables, backend_kwargs, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_backend_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbackend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/backends/zarr.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, append_dim, write_region)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mzarr_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzarr_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate_on_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_region\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/zarr/hierarchy.py\u001b[0m in \u001b[0;36mopen_group\u001b[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontains_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mGroupNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGroupNotFoundError\u001b[0m: group not found at path ''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f677e7f09291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# put basic info in target directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This needs to be done on the FIRST chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/pangeo_forge/recipe.py\u001b[0m in \u001b[0;36m_prepare_target\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"_FillValue\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# actually not necessary if we use decode_times=False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_target_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/pangeo_forge/recipe.py\u001b[0m in \u001b[0;36minitialize_target\u001b[0;34m(self, ds, **expand_dims)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating a new dataset in target\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mtarget_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_zarr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_mapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_target_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_zarr\u001b[0;34m(self, store, chunk_store, mode, synchronizer, group, encoding, compute, consolidated, append_dim, region)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0mconsolidated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconsolidated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0mappend_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mappend_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m             \u001b[0mregion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m         )\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mto_zarr\u001b[0;34m(dataset, store, chunk_store, mode, synchronizer, group, encoding, compute, consolidated, append_dim, region)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0;31m# validate Dataset keys, DataArray names, and attr keys/values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m     \u001b[0m_validate_dataset_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m     \u001b[0m_validate_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36m_validate_attrs\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mcheck_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python/anaconda3/envs/pangeo-forge/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mcheck_attr\u001b[0;34m(name, value)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise TypeError(\n\u001b[0;32m--> 231\u001b[0;31m                 \u001b[0;34mf\"Invalid value for attr {name!r}: {value!r} must be a number, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                 \u001b[0;34m\"a string, an ndarray or a list/tuple of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;34m\"numbers/strings for serialization to netCDF \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid value for attr 'coordinates': Empty(dtype=dtype('S1')) must be a number, a string, an ndarray or a list/tuple of numbers/strings for serialization to netCDF files"
     ]
    }
   ],
   "source": [
    "# put basic info in target directory\n",
    "recipe.prepare_target()  # This needs to be done on the FIRST chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for input_file in recipe.inputs_for_chunk(all_chunks[0]):\n",
    "    print(input_file)\n",
    "    recipe.cache_input(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at the last one:\n",
    "for input_file in recipe.inputs_for_chunk(all_chunks[-1]):\n",
    "    print(input_file)\n",
    "    recipe.cache_input(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_chunk = recipe.open_chunk(all_chunks[0])   \n",
    "print(f'Total chunk size: {ds_chunk.nbytes / 1e6} MB')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store first chunk\n",
    "zgroup = zarr.open(target_dir.name)\n",
    "print(zgroup.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cftime import DatetimeNoLeap\n",
    "recipe.store_chunk(all_chunks[0])\n",
    "zgroup[var].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe.store_chunk(all_chunks[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first chunk\n",
    "ds = xr.open_zarr(target_dir.name)\n",
    "ds[var][0,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hurl = recipe.inputs_for_chunk(all_chunks[-1])[0]\n",
    "url = hurl.replace('fileServer','dodsC')\n",
    "print('source URL = ',url)\n",
    "print('open netcdf dataset')\n",
    "ds = xr.open_dataset(url)\n",
    "print(f\"first time = {ds.time[0]}\")\n",
    "\n",
    "zbdir = 'zarr-tmp'\n",
    "print('save zarr dataset')\n",
    "ds.to_zarr(zbdir, consolidated=True, mode='w')\n",
    "ds2 = xr.open_zarr(zbdir)\n",
    "print(f\"first time = {ds2.time[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo-forge",
   "language": "python",
   "name": "pangeo-forge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
